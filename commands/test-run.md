---
description: 测试运行与修复 ultrathink
---

# 测试运行与修复

> 运行项目测试，识别并修复失败用例

## 输入方式

```bash
/test-run              # 运行所有测试
/test-run unit         # 仅单元测试
/test-run e2e          # 仅 E2E 测试
/test-run $ARGUMENTS
```

---

## 执行流程

### 1. 识别测试环境

- 定位测试命令（package.json / pubspec.yaml / pytest.ini 等）
- 确认测试框架
- 检查测试环境就绪（依赖、服务）

### 2. 运行测试

**输出必须重定向到文件**（避免终端轮询卡死）：
```bash
npm test > /tmp/test-result.txt 2>&1
flutter test > /tmp/test-result.txt 2>&1
```

**大量失败时的应对策略**（>10 个失败）：
1. 先跑快速扫描获取失败概览
2. 聚焦单个失败看完整日志
3. 按目录分批运行
4. 识别共同根因（修一个可能修复多个）

### 3. 诊断失败原因

| 分类 | 示例 | 处理 |
|------|------|------|
| 代码问题 | 业务逻辑错误、边界条件、异步问题 | 修复源代码 |
| 测试问题 | 断言过时、测试数据不正确 | 更新测试 |
| 环境问题 | 数据库连接、配置缺失 | 调整配置 |
| 稳定性问题 | 时序问题、选择器失效 | 优化等待策略 |

### 4. 修复并验证

- 修复后重新运行，确保没有引入新问题
- E2E 多次运行验证稳定性

**死循环熔断**：同一测试修复 **3 次仍失败**时：
1. 停止修复
2. 标记"需要人工介入"
3. 跳过继续处理下一个
4. 记录已尝试的修复方向

---

## 输出格式

```markdown
## 测试执行结果

**类型**: [unit/integration/e2e/all]
**通过**: X | **失败**: Y | **跳过**: Z

### 已修复
1. [测试名] - [问题类型] - [修复说明]

### 遗留问题（如有）
1. [测试名] - [原因] - [建议]
```

---

## 代码优化信号

修复测试时发现以下问题，说明代码需要优化：

| 信号 | 暴露的设计问题 |
|------|---------------|
| 难以 mock | 依赖太多、耦合太紧 |
| setup 复杂 | 接口设计问题 |
| 无法隔离 | 模块耦合 |
| E2E 过于脆弱 | 考虑 Test Facade 绕过 UI |
| E2E 过于缓慢 | 考虑冰山策略（逻辑转移到单元测试）|

---

## 约束

- 优先修复代码 bug，谨慎修改测试用例
- 修改测试前理解原始设计意图
- E2E 使用稳定选择器（data-testid 优先）

## 相关文档

- `/test-plan` - 测试规划（生成 DAG 任务）
- `/test-audit` - 测试基础设施审计
